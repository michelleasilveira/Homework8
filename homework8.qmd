---
title: "Homework 8 - Seoul Bike Rentals — MLR with tidymodels (HW)"
format: html
editor: visual
---

```{r}
#| label: setup-packages
#| message: false
#| warning: false
set.seed(2025)

# Core
library(tidyverse)
library(lubridate)
library(janitor)
library(skimr)

# Viz
library(GGally)

# Modeling
library(tidymodels)
```

# 1) Read the data (with encoding fix) and clean names

```{r}
#| label: read-data
url <- "https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv"

raw_hourly <- readr::read_csv(
  url,
  locale = readr::locale(encoding = "Latin1")   # fixes 'invalid multibyte string'
) %>% 
  janitor::clean_names()

glimpse(raw_hourly)
```

# 2) EDA — types, missingness, factors, rename, subset

```{r}
#| label: eda-prep
# Convert date, set factors, and rename to friendly snake_case
hourly <- raw_hourly %>% 
  mutate(
    date            = lubridate::dmy(date),  # CSV uses day/month/year
    seasons         = factor(seasons, levels = c("Winter","Spring","Summer","Autumn")),
    holiday         = factor(holiday),
    functioning_day = factor(functioning_day)
  ) %>% 
  rename(
    bike_count      = rented_bike_count,
    temp            = temperature_c,
    humidity        = humidity_percent,
    windspeed       = wind_speed_m_s,
    visibility      = visibility_10m,
    dew_point_temp  = dew_point_temperature_c,
    solar_radiation = solar_radiation_mj_m2,
    rainfall        = rainfall_mm,
    snowfall        = snowfall_cm
  )

# Missingness check
missing_tbl <- hourly %>%
  summarise(across(everything(), ~sum(is.na(.)))) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "n_missing") %>%
  arrange(desc(n_missing))

missing_tbl

# Quick structure / summary
skim(hourly)

# Subset to functioning days only (per instructions)
hourly_fun <- filter(hourly, functioning_day == "Yes")
```

# 3) Summarize to **daily** granularity

```{r}
#| label: daily-agg
daily <- hourly_fun %>% 
  group_by(date, seasons, holiday) %>% 
  summarise(
    bike_count      = sum(bike_count, na.rm = TRUE),
    rainfall        = sum(rainfall, na.rm = TRUE),
    snowfall        = sum(snowfall, na.rm = TRUE),
    temp            = mean(temp, na.rm = TRUE),
    humidity        = mean(humidity, na.rm = TRUE),
    windspeed       = mean(windspeed, na.rm = TRUE),
    visibility      = mean(visibility, na.rm = TRUE),
    dew_point_temp  = mean(dew_point_temp, na.rm = TRUE),
    solar_radiation = mean(solar_radiation, na.rm = TRUE),
    .groups = "drop"
  )

skim(daily)
```

## Plots and correlations

```{r}
#| label: eda-plots
# Distribution of daily rentals
ggplot(daily, aes(bike_count)) +
  geom_histogram(bins = 30) +
  labs(title = "Daily Bike Rentals", x = "Count (daily total)")

# Rentals by season
ggplot(daily, aes(seasons, bike_count, fill = seasons)) +
  geom_boxplot(show.legend = FALSE) +
  labs(title = "Bike rentals by season")

# Weather relationships
ggplot(daily, aes(temp, bike_count)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Temperature vs rentals")

ggplot(daily, aes(humidity, bike_count)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Humidity vs rentals")
```

```{r}
#| label: corrs
num_tbl <- daily %>% select(where(is.numeric))
round(cor(num_tbl, use = "pairwise.complete.obs"), 3)
```

# 4) Split data (75/25, stratified by season)

```{r}
#| label: split
set.seed(2025)
split_obj <- rsample::initial_split(daily, prop = 0.75, strata = seasons)
train <- rsample::training(split_obj)
test  <- rsample::testing(split_obj)

set.seed(2025)
cv10 <- rsample::vfold_cv(train, v = 10, strata = seasons)
```

# 5) Recipes

**Recipe 1**: - drop `date` from predictors (keep as ID) - derive **weekday/weekend factor** from date - dummy encode categoricals - standardize numerics

**Recipe 2**: Recipe 1 + interactions: `seasons×holiday`, `seasons×temp`, `temp×rainfall`

**Recipe 3**: Recipe 2 + **quadratic terms** for the continuous numeric predictors

```{r}
#| label: recipes
base_recipe <- function(dat) {
  recipe(bike_count ~ ., data = dat) %>%
    update_role(date, new_role = "ID") %>%
    # Create day-of-week and then a factor as required
    step_date(date, features = "dow", label = TRUE) %>%
    step_mutate(
      day_type = factor(
        if_else(as.character(date_dow) %in% c("Saturday","Sunday"),
                "weekend", "weekday")
      )
    ) %>%
    # Turn the factor into a robust numeric binary and drop the factor & helper
    step_mutate(is_weekend = if_else(day_type == "weekend", 1, 0)) %>%
    step_rm(day_type, date_dow) %>%
    # Dummies for other categoricals only
    step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
    step_zv(all_predictors()) %>%
    # Normalize numerics (or use center+scale if your recipes version needs it)
    step_normalize(all_numeric_predictors())
    # step_center(all_numeric_predictors()) %>% step_scale(all_numeric_predictors())
}

rec1 <- base_recipe(train)

rec2 <- base_recipe(train) %>%
  step_interact(terms = ~ starts_with("seasons_"):starts_with("holiday_") +
                      starts_with("seasons_"):temp +
                      temp:rainfall)

# Apply poly ONLY to continuous predictors (keep this poly fix)
rec3 <- base_recipe(train) %>%
  step_interact(terms = ~ starts_with("seasons_"):starts_with("holiday_") +
                      starts_with("seasons_"):temp +
                      temp:rainfall) %>%
  step_poly(temp, humidity, windspeed, visibility, dew_point_temp,
            solar_radiation, rainfall, snowfall, degree = 2)

```

# 6) Linear model + workflows

```{r}
#| label: workflows
lm_spec <- linear_reg() %>% set_engine("lm")

wf1 <- workflow() %>% add_model(lm_spec) %>% add_recipe(rec1)
wf2 <- workflow() %>% add_model(lm_spec) %>% add_recipe(rec2)
wf3 <- workflow() %>% add_model(lm_spec) %>% add_recipe(rec3)
```

# 7) 10-fold CV and model selection (lowest RMSE)

```{r}
#| label: fit-resamples
metrics <- yardstick::metric_set(rmse, rsq)

set.seed(2025)
res1 <- fit_resamples(wf1, resamples = cv10, metrics = metrics,
                      control = control_resamples(save_pred = TRUE))
set.seed(2025)
res2 <- fit_resamples(wf2, resamples = cv10, metrics = metrics,
                      control = control_resamples(save_pred = TRUE))
set.seed(2025)
res3 <- fit_resamples(wf3, resamples = cv10, metrics = metrics,
                      control = control_resamples(save_pred = TRUE))

cv_summary <- bind_rows(
  collect_metrics(res1) %>% mutate(model = "Recipe 1"),
  collect_metrics(res2) %>% mutate(model = "Recipe 2"),
  collect_metrics(res3) %>% mutate(model = "Recipe 3")
) %>% filter(.metric == "rmse") %>% arrange(mean)

cv_summary
best_model_name <- cv_summary$model[1]
best_model_name
```

# 8) Final fit on training data and test RMSE

```{r}
#| label: last-fit
best_wf <- switch(best_model_name,
                  "Recipe 1" = wf1,
                  "Recipe 2" = wf2,
                  "Recipe 3" = wf3)

final_fit <- last_fit(best_wf, split = split_obj, metrics = metrics)

# Test-set RMSE and R^2
collect_metrics(final_fit)
```

# 9) Final model coefficients (tidy)

```{r}
#| label: coef-table
final_model <- extract_fit_parsnip(final_fit$.workflow[[1]])
broom::tidy(final_model, conf.int = TRUE) %>%
  arrange(desc(abs(estimate))) %>%
  head(30)
```

# 10) Additional models: LASSO, Trees, Bagged Trees, Random Forest

```{r}
#| label: extra-packages
# Extra packages for new models & plots
library(glmnet)      # LASSO engine
library(baguette)    # bagged trees
library(vip)         # variable importance plots
library(rpart.plot)  # regression tree plot
```

## 10.1 Best MLR model from HW8 (baseline for comparison)

```{r}
#| label: mlr-baseline
# Metric set for all new comparisons
reg_metrics <- metric_set(rmse, mae)

# best_wf was defined earlier based on CV RMSE across the 3 recipes
mlr_best_fit <- fit(best_wf, data = train)

mlr_test_pred <- predict(mlr_best_fit, new_data = test) %>%
  bind_cols(test %>% select(bike_count))

mlr_test_metrics <- reg_metrics(
  mlr_test_pred,
  truth   = bike_count,
  estimate = .pred
) %>%
  mutate(model = paste0("Best MLR (", best_model_name, ")"))

mlr_test_metrics
```

```{r}
#| label: mlr-coefs
mlr_best_coefs <- extract_fit_parsnip(mlr_best_fit) %>%
  tidy() %>%
  arrange(desc(abs(estimate)))

head(mlr_best_coefs, 20)
```

## 10.2 LASSO (using Recipe 1)

```{r}
#| label: lasso-tune
lasso_spec <- linear_reg(
  penalty = tune(),
  mixture = 1          # 1 = pure LASSO
) %>%
  set_engine("glmnet")

lasso_wf <- workflow() %>%
  add_model(lasso_spec) %>%
  add_recipe(rec1)

# Simple grid of penalty values
lasso_grid <- grid_regular(penalty(), levels = 30)

set.seed(2025)
lasso_tune <- tune_grid(
  lasso_wf,
  resamples = cv10,
  grid      = lasso_grid,
  metrics   = reg_metrics
)

collect_metrics(lasso_tune)
lasso_best <- select_best(lasso_tune, metric = "rmse")
lasso_best
```

```{r}
#| label: lasso-final
lasso_final_wf  <- finalize_workflow(lasso_wf, lasso_best)
lasso_final_fit <- fit(lasso_final_wf, data = train)

lasso_test_pred <- predict(lasso_final_fit, new_data = test) %>%
  bind_cols(test %>% select(bike_count))

lasso_test_metrics <- reg_metrics(
  lasso_test_pred,
  truth   = bike_count,
  estimate = .pred
) %>%
  mutate(model = "LASSO")

lasso_test_metrics
```

```{r}
#| label: lasso-coefs
lasso_coefs <- extract_fit_parsnip(lasso_final_fit) %>%
  tidy() %>%
  arrange(desc(abs(estimate)))

head(lasso_coefs, 20)
```

## 10.3 Regression Tree (tuned)

```{r}
#| label: tree-tune
tree_spec <- decision_tree(
  cost_complexity = tune(),
  tree_depth      = tune(),
  min_n           = tune()
) %>%
  set_engine("rpart") %>%
  set_mode("regression")

tree_wf <- workflow() %>%
  add_model(tree_spec) %>%
  add_recipe(rec1)

tree_grid <- grid_regular(
  cost_complexity(),
  tree_depth(),
  min_n(),
  levels = c(5, 5, 5)
)

set.seed(2025)
tree_tune <- tune_grid(
  tree_wf,
  resamples = cv10,
  grid      = tree_grid,
  metrics   = reg_metrics
)

collect_metrics(tree_tune)
tree_best <- select_best(tree_tune, metric = "rmse")
tree_best
```

```{r}
#| label: tree-final
tree_final_wf  <- finalize_workflow(tree_wf, tree_best)
tree_final_fit <- fit(tree_final_wf, data = train)

tree_test_pred <- predict(tree_final_fit, new_data = test) %>%
  bind_cols(test %>% select(bike_count))

tree_test_metrics <- reg_metrics(
  tree_test_pred,
  truth   = bike_count,
  estimate = .pred
) %>%
  mutate(model = "Regression Tree")

tree_test_metrics
```

```{r}
#| label: tree-plot
tree_fit_parsnip <- extract_fit_parsnip(tree_final_fit)
rpart.plot::rpart.plot(tree_fit_parsnip$fit)
```

## 10.4 Bagged Trees (tuned)

```{r}
#| label: bagged-tune
bagged_spec <- bag_tree(
  cost_complexity = tune(),
  min_n           = tune()
) %>%
  set_engine("rpart", times = 50) %>%  # 50 bootstrap samples
  set_mode("regression")

bagged_wf <- workflow() %>%
  add_model(bagged_spec) %>%
  add_recipe(rec1)

bagged_grid <- grid_regular(
  cost_complexity(),
  min_n(),
  levels = c(5, 5)
)

set.seed(2025)
bagged_tune <- tune_grid(
  bagged_wf,
  resamples = cv10,
  grid      = bagged_grid,
  metrics   = reg_metrics
)

collect_metrics(bagged_tune)
bagged_best <- select_best(bagged_tune, metric = "rmse")
bagged_best
```

```{r}
#| label: bagged-final
bagged_final_wf  <- finalize_workflow(bagged_wf, bagged_best)
bagged_final_fit <- fit(bagged_final_wf, data = train)

bagged_test_pred <- predict(bagged_final_fit, new_data = test) %>%
  bind_cols(test %>% select(bike_count))

bagged_test_metrics <- reg_metrics(
  bagged_test_pred,
  truth   = bike_count,
  estimate = .pred
) %>%
  mutate(model = "Bagged Trees")

bagged_test_metrics
```

```{r}
#| label: bagged-vip
bagged_fit_parsnip <- extract_fit_parsnip(bagged_final_fit)
vip::vip(bagged_fit_parsnip$fit)
```

## 10.5 Random Forest (tuned)

```{r}
#| label: rf-tune
rf_spec <- rand_forest(
  mtry  = tune(),
  min_n = tune(),
  trees = 500
) %>%
  set_engine("ranger", importance = "permutation") %>%
  set_mode("regression")

# set up mtry range based on predictors
rf_mtry <- finalize(mtry(), train %>% select(-bike_count))

rf_wf <- workflow() %>%
  add_model(rf_spec) %>%
  add_recipe(rec1)

rf_grid <- grid_random(
  rf_mtry,
  min_n(),
  size = 20
)

set.seed(2025)
rf_tune <- tune_grid(
  rf_wf,
  resamples = cv10,
  grid      = rf_grid,
  metrics   = reg_metrics
)

collect_metrics(rf_tune)
rf_best <- select_best(rf_tune, metric = "rmse")
rf_best
```

```{r}
#| label: rf-final
rf_final_wf  <- finalize_workflow(rf_wf, rf_best)
rf_final_fit <- fit(rf_final_wf, data = train)

rf_test_pred <- predict(rf_final_fit, new_data = test) %>%
  bind_cols(test %>% select(bike_count))

rf_test_metrics <- reg_metrics(
  rf_test_pred,
  truth   = bike_count,
  estimate = .pred
) %>%
  mutate(model = "Random Forest")

rf_test_metrics
```

```{r}
#| label: rf-vip
rf_fit_parsnip <- extract_fit_parsnip(rf_final_fit)
vip::vip(rf_fit_parsnip$fit)
```

## 10.6 Compare all final models on the test set

```{r}
#| label: test-compare
all_test_metrics <- bind_rows(
  mlr_test_metrics,
  lasso_test_metrics,
  tree_test_metrics,
  bagged_test_metrics,
  rf_test_metrics
) %>%
  filter(.metric %in% c("rmse", "mae")) %>%
  arrange(.metric, mean)

all_test_metrics
```

```{r}
#| label: best-overall
best_overall <- all_test_metrics %>%
  filter(.metric == "rmse") %>%
  arrange(mean) %>%
  slice(1)

best_overall
overall_best_name <- best_overall$model[[1]]
overall_best_name
```

## 10.7 Fit the overall best model on the entire data set

```{r}
#| label: best-full-fit
overall_best_wf <- switch(
  overall_best_name,
  paste0("Best MLR (", best_model_name, ")") = best_wf,
  "LASSO"           = lasso_final_wf,
  "Regression Tree" = tree_final_wf,
  "Bagged Trees"    = bagged_final_wf,
  "Random Forest"   = rf_final_wf
)

best_full_fit <- fit(overall_best_wf, data = daily)
best_full_fit
```

# Appendix — session info

```{r}
sessionInfo()
```


